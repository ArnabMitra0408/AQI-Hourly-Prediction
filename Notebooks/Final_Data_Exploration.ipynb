{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data=pd.read_csv('../data_store/final_data/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>aqi</th>\n",
       "      <th>state</th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>nh3</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>rain</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_direction_10m</th>\n",
       "      <th>soil_temperature_0_to_7cm</th>\n",
       "      <th>soil_moisture_0_to_7cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-13 07:00:00</td>\n",
       "      <td>32.83</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>198.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>56.51</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.19</td>\n",
       "      <td>16.929998</td>\n",
       "      <td>84.940186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.594208</td>\n",
       "      <td>58.570484</td>\n",
       "      <td>18.279999</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-13 08:00:00</td>\n",
       "      <td>31.95</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>193.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>55.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>17.230000</td>\n",
       "      <td>84.153740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.704336</td>\n",
       "      <td>52.594578</td>\n",
       "      <td>18.230000</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-13 09:00:00</td>\n",
       "      <td>31.57</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>191.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>53.64</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>17.529999</td>\n",
       "      <td>82.841130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.287822</td>\n",
       "      <td>55.619600</td>\n",
       "      <td>18.279999</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-13 10:00:00</td>\n",
       "      <td>31.25</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>190.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>52.21</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.09</td>\n",
       "      <td>17.429998</td>\n",
       "      <td>83.905220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.396570</td>\n",
       "      <td>59.036320</td>\n",
       "      <td>18.279999</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-13 11:00:00</td>\n",
       "      <td>31.38</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>191.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>50.78</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>84.442380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.787991</td>\n",
       "      <td>56.309900</td>\n",
       "      <td>18.230000</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    aqi    state      co   no   no2     o3   so2  pm2_5  \\\n",
       "0  2023-10-13 07:00:00  32.83  Alabama  198.60  0.0  1.05  56.51  0.13   2.84   \n",
       "1  2023-10-13 08:00:00  31.95  Alabama  193.60  0.0  0.79  55.07  0.07   2.74   \n",
       "2  2023-10-13 09:00:00  31.57  Alabama  191.93  0.0  0.67  53.64  0.09   2.81   \n",
       "3  2023-10-13 10:00:00  31.25  Alabama  190.26  0.0  0.70  52.21  0.13   3.05   \n",
       "4  2023-10-13 11:00:00  31.38  Alabama  191.93  0.0  0.79  50.78  0.17   3.35   \n",
       "\n",
       "   pm10   nh3  temperature_2m  relative_humidity_2m  rain  wind_speed_10m  \\\n",
       "0  3.31  0.19       16.929998             84.940186   0.0        7.594208   \n",
       "1  3.21  0.14       17.230000             84.153740   0.0        7.704336   \n",
       "2  3.30  0.11       17.529999             82.841130   0.0        8.287822   \n",
       "3  3.58  0.09       17.429998             83.905220   0.0        8.396570   \n",
       "4  3.92  0.08       17.380000             84.442380   0.0        7.787991   \n",
       "\n",
       "   wind_direction_10m  soil_temperature_0_to_7cm  soil_moisture_0_to_7cm  \n",
       "0           58.570484                  18.279999                   0.445  \n",
       "1           52.594578                  18.230000                   0.445  \n",
       "2           55.619600                  18.279999                   0.444  \n",
       "3           59.036320                  18.279999                   0.443  \n",
       "4           56.309900                  18.230000                   0.443  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Hybrid Model...\n",
      "\n",
      "Preparing data...\n",
      "\n",
      "Training SARIMAX models and computing residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnabmitra/miniconda3/envs/PT_GPU/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/arnabmitra/miniconda3/envs/PT_GPU/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM model...\n",
      "Training LSTM model...\n",
      "Epoch [10/50], Loss: 577.0893\n",
      "Epoch [20/50], Loss: 576.7847\n",
      "Epoch [30/50], Loss: 577.0734\n",
      "Epoch [40/50], Loss: 574.5251\n",
      "Epoch [50/50], Loss: 574.7218\n",
      "\n",
      "Making predictions...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 230\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results, hybrid_model\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Usage example\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m results, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_all_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 205\u001b[0m, in \u001b[0;36mtrain_and_evaluate_all_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    202\u001b[0m hybrid_model\u001b[38;5;241m.\u001b[39mtrain_lstm(train_features, residuals)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMaking predictions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mhybrid_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m hybrid_model\u001b[38;5;241m.\u001b[39mpredict(test_features, test_data)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating model performance...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 177\u001b[0m, in \u001b[0;36mHybridModel.predict\u001b[0;34m(self, features, data_subset)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Pad LSTM predictions\u001b[39;00m\n\u001b[1;32m    176\u001b[0m pad_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 177\u001b[0m lstm_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Combine predictions\u001b[39;00m\n\u001b[1;32m    180\u001b[0m min_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sarimax_pred), \u001b[38;5;28mlen\u001b[39m(lstm_pred))\n",
      "File \u001b[0;32m~/miniconda3/envs/PT_GPU/lib/python3.12/site-packages/numpy/lib/arraypad.py:748\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`pad_width` must be of integral type.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Broadcast to shape (array.ndim, 2)\u001b[39;00m\n\u001b[0;32m--> 748\u001b[0m pad_width \u001b[38;5;241m=\u001b[39m \u001b[43m_as_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(mode):\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# Old behavior: Use user-supplied function with np.apply_along_axis\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     function \u001b[38;5;241m=\u001b[39m mode\n",
      "File \u001b[0;32m~/miniconda3/envs/PT_GPU/lib/python3.12/site-packages/numpy/lib/arraypad.py:522\u001b[0m, in \u001b[0;36m_as_pairs\u001b[0;34m(x, ndim, as_index)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain negative values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;66;03m# Converting the array with `tolist` seems to improve performance\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# when iterating and indexing the result (see usage in `pad`)\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/PT_GPU/lib/python3.12/site-packages/numpy/lib/stride_tricks.py:413\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_broadcast_to_dispatcher, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_to\u001b[39m(array, shape, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    369\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Broadcast an array to a new shape.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m           [1, 2, 3]])\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreadonly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PT_GPU/lib/python3.12/site-packages/numpy/lib/stride_tricks.py:349\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall elements of broadcast shape must be non-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    347\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    348\u001b[0m extras \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 349\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnditer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrefs_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzerosize_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextras\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_flags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreadonly\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitershape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m it:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# never really has writebackifcopy semantics\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     broadcast \u001b[38;5;241m=\u001b[39m it\u001b[38;5;241m.\u001b[39mitviews[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)"
     ]
    }
   ],
   "source": [
    "class AQIDataset(Dataset):\n",
    "    def __init__(self, X, y, sequence_length):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y.reshape(-1, 1))  # Reshape y to match model output\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx:idx + self.sequence_length], \n",
    "                self.y[idx + self.sequence_length - 1])\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                           batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "class HybridModel:\n",
    "    def __init__(self, sequence_length=24, hidden_size=64, num_layers=2):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.lstm_model = None\n",
    "        self.feature_scaler = MinMaxScaler()\n",
    "        self.target_scaler = MinMaxScaler()\n",
    "        \n",
    "        self.order = (1, 1, 1)\n",
    "        self.seasonal_order = (1, 1, 1, 24)\n",
    "        self.sarimax_predictions = None\n",
    "        \n",
    "    def prepare_data(self, data):\n",
    "        # Convert timestamp to datetime and sort\n",
    "        data = data.copy()\n",
    "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "        data = data.sort_values(['state', 'timestamp'])\n",
    "        \n",
    "        # Create features and target\n",
    "        features = data.drop(['aqi', 'state', 'timestamp'], axis=1)\n",
    "        target = data['aqi']\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(data) * 0.8)\n",
    "        train_features = features[:train_size]\n",
    "        test_features = features[train_size:]\n",
    "        train_target = target[:train_size]\n",
    "        test_target = target[train_size:]\n",
    "        \n",
    "        # Scale data\n",
    "        scaled_train_features = self.feature_scaler.fit_transform(train_features)\n",
    "        scaled_test_features = self.feature_scaler.transform(test_features)\n",
    "        scaled_train_target = self.target_scaler.fit_transform(train_target.values.reshape(-1, 1))\n",
    "        scaled_test_target = self.target_scaler.transform(test_target.values.reshape(-1, 1))\n",
    "        \n",
    "        return (scaled_train_features, scaled_test_features, \n",
    "                scaled_train_target, scaled_test_target,\n",
    "                train_target, test_target,\n",
    "                data[:train_size], data[train_size:])\n",
    "    \n",
    "    def train_sarimax(self, train_data):\n",
    "        # Group by state and train SARIMAX for each state\n",
    "        residuals_list = []\n",
    "        \n",
    "        for state in train_data['state'].unique():\n",
    "            state_data = train_data[train_data['state'] == state].copy()\n",
    "            state_data = state_data.set_index('timestamp')\n",
    "            state_data = state_data.asfreq('h')\n",
    "            state_data = state_data.ffill().bfill()\n",
    "            \n",
    "            # Fit SARIMAX model\n",
    "            model = SARIMAX(state_data['aqi'],\n",
    "                          order=self.order,\n",
    "                          seasonal_order=self.seasonal_order,\n",
    "                          enforce_stationarity=False,\n",
    "                          enforce_invertibility=False)\n",
    "            \n",
    "            try:\n",
    "                fitted_model = model.fit(disp=False)\n",
    "                predictions = fitted_model.get_prediction(start=0)\n",
    "                state_residuals = state_data['aqi'] - predictions.predicted_mean\n",
    "                residuals_list.append(state_residuals)\n",
    "            except Exception as e:\n",
    "                print(f\"SARIMAX fitting error for state {state}: {str(e)}\")\n",
    "                # If SARIMAX fails, use simple differencing\n",
    "                state_residuals = state_data['aqi'].diff().fillna(0)\n",
    "                residuals_list.append(state_residuals)\n",
    "        \n",
    "        # Combine all residuals\n",
    "        all_residuals = pd.concat(residuals_list)\n",
    "        all_residuals = all_residuals.sort_index()\n",
    "        \n",
    "        return all_residuals.values\n",
    "    \n",
    "    def train_lstm(self, features, residuals, epochs=50, batch_size=32):\n",
    "        dataset = AQIDataset(features, residuals, self.sequence_length)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        if self.lstm_model is None:\n",
    "            input_size = features.shape[1]\n",
    "            self.lstm_model = LSTMModel(input_size, self.hidden_size, self.num_layers).to(self.device)\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.lstm_model.parameters())\n",
    "        \n",
    "        print(\"Training LSTM model...\")\n",
    "        self.lstm_model.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for batch_X, batch_y in dataloader:\n",
    "                batch_X = batch_X.to(self.device)\n",
    "                batch_y = batch_y.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.lstm_model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader):.4f}')\n",
    "    \n",
    "    def predict(self, features, data_subset):\n",
    "        predictions_list = []\n",
    "        \n",
    "        for state in data_subset['state'].unique():\n",
    "            state_mask = data_subset['state'] == state\n",
    "            state_data = data_subset[state_mask].copy()\n",
    "            state_data = state_data.set_index('timestamp')\n",
    "            state_data = state_data.asfreq('h')\n",
    "            state_data = state_data.ffill().bfill()\n",
    "            \n",
    "            try:\n",
    "                # SARIMAX prediction\n",
    "                model = SARIMAX(state_data['aqi'],\n",
    "                              order=self.order,\n",
    "                              seasonal_order=self.seasonal_order,\n",
    "                              enforce_stationarity=False,\n",
    "                              enforce_invertibility=False)\n",
    "                fitted_model = model.fit(disp=False)\n",
    "                sarimax_pred = fitted_model.get_prediction(start=0)\n",
    "                sarimax_pred = sarimax_pred.predicted_mean.values.reshape(-1, 1)\n",
    "            except Exception as e:\n",
    "                print(f\"SARIMAX prediction error for state {state}: {str(e)}\")\n",
    "                # Use simple moving average as fallback\n",
    "                sarimax_pred = state_data['aqi'].rolling(window=24, min_periods=1).mean().values.reshape(-1, 1)\n",
    "            \n",
    "            # LSTM prediction\n",
    "            state_features = features[state_mask]\n",
    "            lstm_predictions = []\n",
    "            \n",
    "            self.lstm_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for i in range(len(state_features) - self.sequence_length + 1):\n",
    "                    sequence = torch.FloatTensor(\n",
    "                        state_features[i:i + self.sequence_length]).unsqueeze(0).to(self.device)\n",
    "                    pred = self.lstm_model(sequence)\n",
    "                    lstm_predictions.append(pred.cpu().numpy())\n",
    "            \n",
    "            # Pad LSTM predictions\n",
    "            pad_length = self.sequence_length - 1\n",
    "            lstm_pred = np.pad(lstm_predictions, ((pad_length, 0), (0, 0)), mode='edge')\n",
    "            \n",
    "            # Combine predictions\n",
    "            min_len = min(len(sarimax_pred), len(lstm_pred))\n",
    "            state_predictions = sarimax_pred[:min_len] + lstm_pred[:min_len]\n",
    "            predictions_list.append(state_predictions)\n",
    "        \n",
    "        # Combine all predictions\n",
    "        all_predictions = np.vstack(predictions_list)\n",
    "        return self.target_scaler.inverse_transform(all_predictions)\n",
    "\n",
    "def train_and_evaluate_all_data(data):\n",
    "    print(\"Initializing Hybrid Model...\")\n",
    "    hybrid_model = HybridModel()\n",
    "    \n",
    "    print(\"\\nPreparing data...\")\n",
    "    (train_features, test_features, \n",
    "     train_target, test_target,\n",
    "     original_train_target, original_test_target,\n",
    "     train_data, test_data) = hybrid_model.prepare_data(data)\n",
    "    \n",
    "    print(\"\\nTraining SARIMAX models and computing residuals...\")\n",
    "    residuals = hybrid_model.train_sarimax(train_data)\n",
    "    \n",
    "    print(\"\\nTraining LSTM model...\")\n",
    "    hybrid_model.train_lstm(train_features, residuals)\n",
    "    \n",
    "    print(\"\\nMaking predictions...\")\n",
    "    train_pred = hybrid_model.predict(train_features, train_data)\n",
    "    test_pred = hybrid_model.predict(test_features, test_data)\n",
    "    \n",
    "    print(\"\\nEvaluating model performance...\")\n",
    "    train_metrics = hybrid_model.evaluate(original_train_target.values, train_pred)\n",
    "    test_metrics = hybrid_model.evaluate(original_test_target.values, test_pred)\n",
    "    \n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"Train RMSE: {train_metrics['rmse']:.4f}\")\n",
    "    print(f\"Test RMSE: {test_metrics['rmse']:.4f}\")\n",
    "    print(f\"Train R2: {train_metrics['r2']:.4f}\")\n",
    "    print(f\"Test R2: {test_metrics['r2']:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    print(\"\\nSaving model...\")\n",
    "    hybrid_model.save_model('models/combined_model')\n",
    "    \n",
    "    results = {\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics\n",
    "    }\n",
    "    \n",
    "    return results, hybrid_model\n",
    "\n",
    "# Usage example\n",
    "results, model = train_and_evaluate_all_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
